{
  "system": {
    "name": "Tasker",
    "language": "Go",
    "description": "A powerful and flexible Go library for efficient concurrent task management, featuring a customizable worker pool, dynamic scaling, priority queuing, and robust resource lifecycle management.",
    "keyFeatures": [
      "Concurrent Task Execution",
      "Generic Resource Management",
      "Rate-Based Dynamic Worker Scaling",
      "Priority Queues",
      "Immediate Task Execution with Resource Pooling (`RunTask`)",
      "Customizable Health Checks & Retries",
      "\"At-Most-Once\" Task Execution",
      "Graceful & Immediate Shutdown",
      "Real-time Performance Metrics",
      "Custom Logging"
    ]
  },
  "dependencies": {
    "external": [
      {
        "name": "github.com/asaidimu/tasker",
        "purpose": "The core Tasker library itself; used as a dependency in example applications. Provides the TaskManager interface and implementation.",
        "interfaces": [
          {
            "name": "TaskManager",
            "description": "The primary interface for managing asynchronous and synchronous task execution within a pool of workers and resources.",
            "methods": [
              {
                "name": "QueueTask",
                "signature": "QueueTask(task func(R) (E, error)) (E, error)",
                "parameters": "task: A function representing the task's logic, accepting a resource of type `R` and returning a result `E` or an error.",
                "returnValue": "Returns the task's result of type `E` and any error encountered during execution. The call blocks until completion."
              },
              {
                "name": "RunTask",
                "signature": "RunTask(task func(R) (E, error)) (E, error)",
                "parameters": "task: A function representing the task's logic, accepting a resource of type `R` and returning a result `E` or an error.",
                "returnValue": "Returns the task's result of type `E` and any error encountered during execution. The call blocks until completion."
              },
              {
                "name": "QueueTaskWithPriority",
                "signature": "QueueTaskWithPriority(task func(R) (E, error)) (E, error)",
                "parameters": "task: A function representing the task's high-priority logic, accepting a resource of type `R` and returning a result `E` or an error.",
                "returnValue": "Returns the task's result of type `E` and any error encountered during execution. The call blocks until completion."
              },
              {
                "name": "QueueTaskOnce",
                "signature": "QueueTaskOnce(task func(R) (E, error)) (E, error)",
                "parameters": "task: A function representing the task's logic, accepting a resource of type `R` and returning a result `E` or an error. This task will not be re-queued if `CheckHealth` indicates an unhealthy state.",
                "returnValue": "Returns the task's result of type `E` and any error encountered during execution. The call blocks until completion."
              },
              {
                "name": "QueueTaskWithPriorityOnce",
                "signature": "QueueTaskWithPriorityOnce(task func(R) (E, error)) (E, error)",
                "parameters": "task: A function representing the task's high-priority logic, accepting a resource of type `R` and returning a result `E` or an error. This task will not be re-queued if `CheckHealth` indicates an unhealthy state.",
                "returnValue": "Returns the task's result of type `E` and any error encountered during execution. The call blocks until completion."
              },
              {
                "name": "Stop",
                "signature": "Stop() error",
                "parameters": "None.",
                "returnValue": "Returns an error if the manager is already stopping or killed, otherwise nil."
              },
              {
                "name": "Kill",
                "signature": "Kill() error",
                "parameters": "None.",
                "returnValue": "Returns an error if the manager is already killed, otherwise nil."
              },
              {
                "name": "Stats",
                "signature": "Stats() TaskStats",
                "parameters": "None.",
                "returnValue": "Returns a `TaskStats` struct containing current operational statistics."
              },
              {
                "name": "Metrics",
                "signature": "Metrics() TaskMetrics",
                "parameters": "None.",
                "returnValue": "Returns a `TaskMetrics` struct containing aggregated performance metrics."
              }
            ]
          },
          {
            "name": "Logger",
            "description": "Interface for custom logging within Tasker. Users can provide their own implementation.",
            "methods": [
              {
                "name": "Debugf",
                "signature": "Debugf(format string, args ...any)",
                "parameters": "format: Format string; args: Arguments for formatting.",
                "returnValue": "None."
              },
              {
                "name": "Infof",
                "signature": "Infof(format string, args ...any)",
                "parameters": "format: Format string; args: Arguments for formatting.",
                "returnValue": "None."
              },
              {
                "name": "Warnf",
                "signature": "Warnf(format string, args ...any)",
                "parameters": "format: Format string; args: Arguments for formatting.",
                "returnValue": "None."
              },
              {
                "name": "Errorf",
                "signature": "Errorf(format string, args ...any)",
                "parameters": "format: Format string; args: Arguments for formatting.",
                "returnValue": "None."
              }
            ]
          },
          {
            "name": "MetricsCollector",
            "description": "Interface for collecting and calculating performance and reliability metrics for the TaskManager. Users can provide their own implementation.",
            "methods": [
              {
                "name": "RecordArrival",
                "signature": "RecordArrival()",
                "parameters": "None.",
                "returnValue": "None."
              },
              {
                "name": "RecordCompletion",
                "signature": "RecordCompletion(stamps TaskLifecycleTimestamps)",
                "parameters": "stamps: `TaskLifecycleTimestamps` containing queued, started, and finished times for a completed task.",
                "returnValue": "None."
              },
              {
                "name": "RecordFailure",
                "signature": "RecordFailure(stamps TaskLifecycleTimestamps)",
                "parameters": "stamps: `TaskLifecycleTimestamps` containing queued, started, and finished times for a failed task.",
                "returnValue": "None."
              },
              {
                "name": "RecordRetry",
                "signature": "RecordRetry()",
                "parameters": "None.",
                "returnValue": "None."
              },
              {
                "name": "Metrics",
                "signature": "Metrics() TaskMetrics",
                "parameters": "None.",
                "returnValue": "Returns a `TaskMetrics` struct containing a snapshot of aggregated performance metrics."
              }
            ]
          }
        ],
        "installation": "go get github.com/asaidimu/tasker",
        "version": ">=1.0.0"
      },
      {
        "name": "context",
        "purpose": "Go standard library package for carrying deadlines, cancellation signals, and other request-scoped values across API boundaries and between goroutines.",
        "interfaces": [
          {
            "name": "context.Context",
            "description": "The fundamental interface for context propagation in Go.",
            "methods": [
              {
                "name": "Done",
                "signature": "Done() <-chan struct{}",
                "parameters": "None.",
                "returnValue": "Returns a channel that is closed when the context is cancelled or times out."
              },
              {
                "name": "Err",
                "signature": "Err() error",
                "parameters": "None.",
                "returnValue": "Returns a non-nil error if Done is closed, specifying why the context was cancelled (e.g., `Canceled` or `DeadlineExceeded`)."
              }
            ]
          }
        ],
        "installation": "Built-in to Go standard library.",
        "version": ">=1.24.3 (Go version)"
      },
      {
        "name": "errors",
        "purpose": "Go standard library package for error handling, including creating new errors and unwrapping them.",
        "interfaces": [],
        "installation": "Built-in to Go standard library.",
        "version": ">=1.24.3 (Go version)"
      },
      {
        "name": "fmt",
        "purpose": "Go standard library package for formatted I/O.",
        "interfaces": [],
        "installation": "Built-in to Go standard library.",
        "version": ">=1.24.3 (Go version)"
      },
      {
        "name": "log",
        "purpose": "Go standard library package for simple logging.",
        "interfaces": [],
        "installation": "Built-in to Go standard library.",
        "version": ">=1.24.3 (Go version)"
      },
      {
        "name": "math",
        "purpose": "Go standard library package for common mathematical functions.",
        "interfaces": [],
        "installation": "Built-in to Go standard library.",
        "version": ">=1.24.3 (Go version)"
      },
      {
        "name": "math/rand",
        "purpose": "Go standard library package for pseudo-random number generation.",
        "interfaces": [],
        "installation": "Built-in to Go standard library.",
        "version": ">=1.24.3 (Go version)"
      },
      {
        "name": "sort",
        "purpose": "Go standard library package for sorting slices and user-defined collections.",
        "interfaces": [],
        "installation": "Built-in to Go standard library.",
        "version": ">=1.24.3 (Go version)"
      },
      {
        "name": "sync",
        "purpose": "Go standard library package for basic synchronization primitives like mutexes and wait groups.",
        "interfaces": [],
        "installation": "Built-in to Go standard library.",
        "version": ">=1.24.3 (Go version)"
      },
      {
        "name": "sync/atomic",
        "purpose": "Go standard library package for low-level atomic memory primitives.",
        "interfaces": [],
        "installation": "Built-in to Go standard library.",
        "version": ">=1.24.3 (Go version)"
      },
      {
        "name": "time",
        "purpose": "Go standard library package for measuring and displaying time.",
        "interfaces": [],
        "installation": "Built-in to Go standard library.",
        "version": ">=1.24.3 (Go version)"
      }
    ],
    "peer": [
      {
        "name": "Go Runtime",
        "reason": "Required for compiling and running Tasker applications. Tasker leverages Go's concurrency primitives (goroutines, channels) directly.",
        "version": ">=1.24.3"
      }
    ]
  },
  "integration": {
    "environmentRequirements": "To use Tasker, you need a Go development environment with Go version 1.24.3 or higher. Tasker itself is cross-platform, so it runs wherever Go is supported (Linux, Windows, macOS, etc.). No special compiler settings are required beyond standard Go build practices.",
    "initializationPatterns": [
      {
        "description": "Standard initialization of Tasker with custom resource lifecycle functions and basic worker configuration. This pattern demonstrates the minimum required setup for a functional TaskManager.",
        "codeExample": "package main\n\nimport (\n\t\"context\"\n\t\"log\"\n\t\"time\"\n\n\t\"github.com/asaidimu/tasker\"\n)\n\n// Define your custom resource type\ntype DatabaseConnection struct { ID int }\n\n// onCreate: Function to create a new database connection\nfunc createDBConnection() (*DatabaseConnection, error) {\n\tlog.Println(\"INFO: Creating DatabaseConnection\")\n\t// Simulate connecting to a database\n\ttime.Sleep(10 * time.Millisecond)\n\treturn &DatabaseConnection{ID: 123}, nil\n}\n\n// onDestroy: Function to close the database connection\nfunc destroyDBConnection(conn *DatabaseConnection) error {\n\tlog.Printf(\"INFO: Destroying DatabaseConnection %d\\n\", conn.ID)\n\t// Simulate closing the connection\n\treturn nil\n}\n\nfunc main() {\n\t// Create a background context for the TaskManager\n\tctx := context.Background()\n\n\t// Configure the TaskManager\n\tconfig := tasker.Config[*DatabaseConnection]{\n\t\tOnCreate:    createDBConnection,    // Required: function to create resource\n\t\tOnDestroy:   destroyDBConnection,   // Required: function to destroy resource\n\t\tWorkerCount: 5,                     // Required: number of base workers\n\t\tCtx:         ctx,                   // Required: parent context for lifecycle\n\t\t// Optional fields:\n\t\t// MaxWorkerCount: 10,\n\t\t// BurstInterval: 100 * time.Millisecond,\n\t\t// CheckHealth: func(err error) bool { return true },\n\t\t// MaxRetries: 3,\n\t\t// ResourcePoolSize: 5,\n\t\t// Logger: &myCustomLogger{},\n\t\t// Collector: &myCustomMetricsCollector{},\n\t}\n\n\t// Create a new TaskManager instance\n\tmanager, err := tasker.NewTaskManager[*DatabaseConnection, string](config) // Tasks will return string results\n\tif err != nil {\n\t\tlog.Fatalf(\"Failed to create TaskManager: %v\", err)\n\t}\n\n\t// Ensure graceful shutdown when main exits\n\tdefer manager.Stop()\n\n\tlog.Println(\"TaskManager initialized and running. Add tasks here.\")\n\t// Example task (non-blocking for main)\n\tgo func() {\n\t\t_, err := manager.QueueTask(func(db *DatabaseConnection) (string, error) {\n\t\t\tlog.Printf(\"Worker processing database query with connection %d\\n\", db.ID)\n\t\t\ttime.Sleep(50 * time.Millisecond)\n\t\t\treturn \"Query result\", nil\n\t\t})\n\t\tif err != nil { log.Printf(\"Task failed: %v\\n\", err) }\n\t\telse { log.Println(\"Task completed.\") }\n\t}()\n\n\ttime.Sleep(200 * time.Millisecond) // Allow time for tasks\n}\n"
      }
    ],
    "commonPitfalls": [
      {
        "issue": "Blocking operations in `OnCreate` or `OnDestroy`",
        "solution": "`OnCreate` and `OnDestroy` functions should be non-blocking and execute quickly. Blocking operations can delay worker startup/shutdown, leading to performance issues or graceful shutdown hangs. If an operation *must* block (e.g., waiting for an external service to become available on startup), consider handling it with timeouts or asynchronous initialization outside these functions where possible. Make sure `OnDestroy` never deadlocks or waits indefinitely."
      },
      {
        "issue": "Task functions that do not respect context cancellation",
        "solution": "For long-running tasks, if you want them to be interruptible during `manager.Stop()` or `manager.Kill()`, your task function's internal logic needs to periodically check a `context.Context.Done()` channel and return if it's closed. Tasker itself doesn't directly pass a context to your `func(R) (E, error)`, so you must manage context propagation within your application (e.g., by capturing a context in a closure)."
      },
      {
        "issue": "Incorrect `CheckHealth` logic leading to worker thrashing",
        "solution": "If your `CheckHealth` function returns `false` for every task error (even transient ones), it can cause workers to be constantly replaced (`OnDestroy` then `OnCreate`), leading to high resource churn and degraded performance. Ensure `CheckHealth` returns `false` only for errors that truly indicate an unhealthy, unrecoverable worker or resource state, not for recoverable task-specific failures."
      },
      {
        "issue": "Queueing tasks after manager shutdown",
        "solution": "Attempting to call `QueueTask`, `RunTask`, etc., after `manager.Stop()` or `manager.Kill()` has been invoked will immediately return an error (`task manager is shutting down`). Ensure your application's task submission logic is aware of the TaskManager's lifecycle and ceases submissions during shutdown."
      }
    ],
    "lifecycleDependencies": "The Tasker's lifecycle is managed by the `context.Context` provided in `Config.Ctx`. When this context is cancelled (either explicitly by your application or implicitly by `manager.Stop()`/`manager.Kill()`), it signals all internal goroutines (workers, burst manager) to begin their shutdown procedures. Workers will call `OnDestroy` on their associated resources as they exit. The `NewTaskManager` function itself calls `OnCreate` to populate the initial `resourcePool` and for each base worker, so `OnCreate` must be ready before `NewTaskManager` is called."
  },
  "types": {
    "Config[R]": {
      "id": "type:Config[R]",
      "definition": "type Config[R any] struct {\n    OnCreate func() (R, error)\n    OnDestroy func(R) error\n    WorkerCount int\n    Ctx context.Context\n    CheckHealth func(error) bool\n    MaxWorkerCount int\n    BurstInterval time.Duration\n    MaxRetries int\n    ResourcePoolSize int\n    Logger Logger\n    Collector MetricsCollector\n    BurstTaskThreshold int `deprecated`\n    BurstWorkerCount int `deprecated`\n}",
      "purpose": "Configures the behavior and parameters for a new `TaskManager` instance, including resource management, worker scaling, and error handling policies.",
      "related": {
        "methods": [
          "method:NewTaskManager"
        ],
        "patterns": []
      },
      "interfaceContract": {
        "requiredMethods": [],
        "optionalMethods": [],
        "parameterObjectStructures": {
          "OnCreate": "func() (R, error) - Function to create a new resource of type `R`. Required.",
          "OnDestroy": "func(R) error - Function to destroy a resource of type `R`. Required.",
          "WorkerCount": "int - Initial and minimum number of base workers. Must be > 0. Required.",
          "Ctx": "context.Context - Parent context for the TaskManager. Required.",
          "CheckHealth": "func(error) bool - Optional function to determine if an error indicates an unhealthy worker/resource. Default: always returns true.",
          "MaxWorkerCount": "int - Maximum total workers (base + burst). Default: `WorkerCount * 2`.",
          "BurstInterval": "time.Duration - Frequency for burst manager checks. Default: 100ms. Set to 0 to disable bursting.",
          "MaxRetries": "int - Max retries for a task on unhealthy errors. Default: 3. Set to 0 for no retries.",
          "ResourcePoolSize": "int - Number of resources to pre-allocate for `RunTask`. Default: `WorkerCount`.",
          "Logger": "Logger - Custom logger implementation. Default: no-op logger.",
          "Collector": "MetricsCollector - Custom metrics collector. Default: internal collector."
        }
      }
    },
    "Logger": {
      "id": "type:Logger",
      "definition": "type Logger interface {\n    Debugf(format string, args ...any)\n    Infof(format string, args ...any)\n    Warnf(format string, args ...any)\n    Errorf(format string, args ...any)\n}",
      "purpose": "Defines the interface for logging messages from the TaskManager, allowing users to integrate their own preferred logging library.",
      "related": {
        "methods": [],
        "patterns": [
          "pattern:Custom Logging"
        ]
      },
      "interfaceContract": {
        "requiredMethods": [
          {
            "name": "Debugf",
            "signature": "Debugf(format string, args ...any)",
            "parameters": "format: A format string for the log message; args: Variadic arguments for the format string.",
            "returnValue": "None.",
            "sideEffects": "Logs a debug-level message to the configured output."
          },
          {
            "name": "Infof",
            "signature": "Infof(format string, args ...any)",
            "parameters": "format: A format string for the log message; args: Variadic arguments for the format string.",
            "returnValue": "None.",
            "sideEffects": "Logs an info-level message to the configured output."
          },
          {
            "name": "Warnf",
            "signature": "Warnf(format string, args ...any)",
            "parameters": "format: A format string for the log message; args: Variadic arguments for the format string.",
            "returnValue": "None.",
            "sideEffects": "Logs a warning-level message to the configured output."
          },
          {
            "name": "Errorf",
            "signature": "Errorf(format string, args ...any)",
            "parameters": "format: A format string for the log message; args: Variadic arguments for the format string.",
            "returnValue": "None.",
            "sideEffects": "Logs an error-level message to the configured output."
          }
        ],
        "optionalMethods": [],
        "parameterObjectStructures": {}
      }
    },
    "MetricsCollector": {
      "id": "type:MetricsCollector",
      "definition": "type MetricsCollector interface {\n    RecordArrival()\n    RecordCompletion(stamps TaskLifecycleTimestamps)\n    RecordFailure(stamps TaskLifecycleTimestamps)\n    RecordRetry()\n    Metrics() TaskMetrics\n}",
      "purpose": "Defines the interface for collecting and calculating performance and reliability metrics for the TaskManager, enabling integration with external monitoring systems.",
      "related": {
        "methods": [],
        "patterns": [
          "pattern:Custom Metrics"
        ]
      },
      "interfaceContract": {
        "requiredMethods": [
          {
            "name": "RecordArrival",
            "signature": "RecordArrival()",
            "parameters": "None.",
            "returnValue": "None.",
            "sideEffects": "Increments a counter for total tasks arrived, used for arrival rate calculation."
          },
          {
            "name": "RecordCompletion",
            "signature": "RecordCompletion(stamps TaskLifecycleTimestamps)",
            "parameters": "stamps: `TaskLifecycleTimestamps` struct containing `QueuedAt`, `StartedAt`, and `FinishedAt` times.",
            "returnValue": "None.",
            "sideEffects": "Updates internal counters for completed tasks and aggregates execution/wait times for latency metrics."
          },
          {
            "name": "RecordFailure",
            "signature": "RecordFailure(stamps TaskLifecycleTimestamps)",
            "parameters": "stamps: `TaskLifecycleTimestamps` struct containing `QueuedAt`, `StartedAt`, and `FinishedAt` times.",
            "returnValue": "None.",
            "sideEffects": "Increments a counter for total tasks failed."
          },
          {
            "name": "RecordRetry",
            "signature": "RecordRetry()",
            "parameters": "None.",
            "returnValue": "None.",
            "sideEffects": "Increments a counter for total tasks retried."
          },
          {
            "name": "Metrics",
            "signature": "Metrics() TaskMetrics",
            "parameters": "None.",
            "returnValue": "Returns a `TaskMetrics` struct containing aggregated performance metrics.",
            "sideEffects": "Calculates and returns a snapshot of current metrics based on collected data."
          }
        ],
        "optionalMethods": [],
        "parameterObjectStructures": {}
      }
    },
    "TaskStats": {
      "id": "type:TaskStats",
      "definition": "type TaskStats struct {\n    BaseWorkers int32\n    ActiveWorkers int32\n    BurstWorkers int32\n    QueuedTasks int32\n    PriorityTasks int32\n    AvailableResources int32\n}",
      "purpose": "Provides a real-time snapshot of the `TaskManager`'s current operational state, including worker counts, queued tasks, and resource availability.",
      "related": {
        "methods": [
          "method:Stats"
        ],
        "patterns": []
      },
      "interfaceContract": {
        "requiredMethods": [],
        "optionalMethods": [],
        "parameterObjectStructures": {
          "BaseWorkers": "int32 - Number of permanently active workers configured.",
          "ActiveWorkers": "int32 - Total number of currently active workers (base + dynamically scaled/burst workers).",
          "BurstWorkers": "int32 - Number of dynamically scaled-up workers currently active.",
          "QueuedTasks": "int32 - Number of tasks currently waiting in the main queue.",
          "PriorityTasks": "int32 - Number of tasks currently waiting in the priority queue.",
          "AvailableResources": "int32 - Number of resources currently available in the internal pool for `RunTask` operations."
        }
      }
    },
    "TaskMetrics": {
      "id": "type:TaskMetrics",
      "definition": "type TaskMetrics struct {\n    AverageExecutionTime time.Duration\n    MinExecutionTime time.Duration\n    MaxExecutionTime time.Duration\n    P95ExecutionTime time.Duration\n    P99ExecutionTime time.Duration\n    AverageWaitTime time.Duration\n    TaskArrivalRate float64\n    TaskCompletionRate float64\n    TotalTasksCompleted uint64\n    TotalTasksFailed uint64\n    TotalTasksRetried uint64\n    SuccessRate float64\n    FailureRate float64\n}",
      "purpose": "Provides a comprehensive snapshot of performance, throughput, and reliability metrics for a `TaskManager` instance, offering deep insights into the behavior of the task execution system over time.",
      "related": {
        "methods": [
          "method:Metrics"
        ],
        "patterns": []
      },
      "interfaceContract": {
        "requiredMethods": [],
        "optionalMethods": [],
        "parameterObjectStructures": {
          "AverageExecutionTime": "time.Duration - Average time spent executing a task.",
          "MinExecutionTime": "time.Duration - Shortest task execution time recorded.",
          "MaxExecutionTime": "time.Duration - Longest task execution time recorded.",
          "P95ExecutionTime": "time.Duration - 95th percentile of task execution time.",
          "P99ExecutionTime": "time.Duration - 99th percentile of task execution time.",
          "AverageWaitTime": "time.Duration - Average time a task spends in a queue before execution.",
          "TaskArrivalRate": "float64 - Number of new tasks added to queues per second.",
          "TaskCompletionRate": "float64 - Number of tasks successfully completed per second.",
          "TotalTasksCompleted": "uint64 - Total count of tasks completed successfully since TaskManager started.",
          "TotalTasksFailed": "uint64 - Total count of tasks that failed permanently (all retries exhausted).",
          "TotalTasksRetried": "uint64 - Total number of times any task was re-queued for retry.",
          "SuccessRate": "float64 - Ratio of successfully completed tasks to total terminal tasks (0.0 to 1.0).",
          "FailureRate": "float64 - Ratio of failed tasks to total terminal tasks (0.0 to 1.0)."
        }
      }
    },
    "TaskLifecycleTimestamps": {
      "id": "type:TaskLifecycleTimestamps",
      "definition": "type TaskLifecycleTimestamps struct {\n    QueuedAt time.Time\n    StartedAt time.Time\n    FinishedAt time.Time\n}",
      "purpose": "Holds critical timestamps for a task's journey, used by `MetricsCollector` implementations to calculate performance metrics.",
      "related": {
        "methods": [
          "method:RecordCompletion",
          "method:RecordFailure"
        ],
        "patterns": []
      },
      "interfaceContract": {
        "requiredMethods": [],
        "optionalMethods": [],
        "parameterObjectStructures": {
          "QueuedAt": "time.Time - Timestamp when the task was first added to a queue.",
          "StartedAt": "time.Time - Timestamp when a worker began executing the task.",
          "FinishedAt": "time.Time - Timestamp when the task execution completed (successfully or not)."
        }
      }
    }
  },
  "methods": {
    "NewTaskManager": {
      "id": "method:NewTaskManager",
      "useCase": "To initialize and start a new concurrent task management system with a pool of workers and resources.",
      "signature": "NewTaskManager[R any, E any](config Config[R]) (TaskManager[R, E], error)",
      "parameters": "config: `Config[R]` struct containing all necessary parameters for TaskManager setup, including resource creation/destruction functions, worker counts, contexts, and optional health checks/metrics.",
      "prerequisites": "`config.WorkerCount` must be > 0. `config.OnCreate` and `config.OnDestroy` must be non-nil functions. `config.Ctx` must be a valid `context.Context`.",
      "sideEffects": "Initializes `ResourcePoolSize` resources, starts `WorkerCount` base worker goroutines, and starts a burst manager goroutine (if `BurstInterval` > 0).",
      "returnValue": "Returns a `TaskManager[R, E]` interface instance ready to accept tasks, or an error if initialization fails (e.g., invalid config, resource creation failure).",
      "exceptions": [
        "errors.New(\"worker count must be positive\")",
        "errors.New(\"onCreate function is required\")",
        "errors.New(\"onDestroy function is required\")",
        "fmt.Errorf(\"failed to initialize resource pool: %w\", originalErr)"
      ],
      "availability": "sync",
      "status": "active",
      "related": {
        "types": [
          "type:Config[R]",
          "type:TaskManager"
        ],
        "patterns": [
          "pattern:Basic TaskManager Initialization"
        ],
        "errors": []
      }
    },
    "NewCollector": {
      "id": "method:NewCollector",
      "useCase": "To create a default, in-memory implementation of the `MetricsCollector` interface. This is typically used internally by `NewTaskManager` if no custom collector is provided.",
      "signature": "NewCollector() MetricsCollector",
      "parameters": "None.",
      "prerequisites": "None.",
      "sideEffects": "Initializes a collector with `startTime` set to the current time.",
      "returnValue": "Returns a `MetricsCollector` interface instance.",
      "exceptions": [],
      "availability": "sync",
      "status": "active",
      "related": {
        "types": [
          "type:MetricsCollector",
          "type:TaskMetrics"
        ],
        "patterns": [],
        "errors": []
      }
    },
    "QueueTask": {
      "id": "method:QueueTask",
      "useCase": "To submit a standard asynchronous task for execution by an available worker. The caller blocks until the task completes.",
      "signature": "QueueTask[R any, E any](task func(R) (E, error)) (E, error)",
      "parameters": "task: A function `func(R) (E, error)` encapsulating the work to be done. It receives a resource of type `R` and returns a result `E` or an error.",
      "prerequisites": "The `TaskManager` must be in a running state.",
      "sideEffects": "Adds the task to the main queue. Increments `QueuedTasks` and triggers `MetricsCollector.RecordArrival()`. Upon completion, decrements `QueuedTasks` and triggers `MetricsCollector.RecordCompletion()` or `RecordFailure()`.",
      "returnValue": "Returns the result `E` from the task's execution and any error `error` that occurred.",
      "exceptions": [
        "errors.New(\"task manager is shutting down\")"
      ],
      "availability": "sync",
      "status": "active",
      "related": {
        "types": [
          "type:Task"
        ],
        "patterns": [
          "pattern:Queue task in a goroutine"
        ],
        "errors": [
          "error:task manager is shutting down",
          "error:max retries exceeded"
        ]
      }
    },
    "QueueTaskOnce": {
      "id": "method:QueueTaskOnce",
      "useCase": "To submit a standard asynchronous task that, if it fails and `CheckHealth` indicates an unhealthy worker, will NOT be re-queued by Tasker's internal retry mechanism. Useful for non-idempotent operations.",
      "signature": "QueueTaskOnce[R any, E any](task func(R) (E, error)) (E, error)",
      "parameters": "task: A function `func(R) (E, error)` encapsulating the work to be done. It receives a resource of type `R` and returns a result `E` or an error.",
      "prerequisites": "The `TaskManager` must be in a running state.",
      "sideEffects": "Adds the task to the main queue. Increments `QueuedTasks` and triggers `MetricsCollector.RecordArrival()`. Upon completion, decrements `QueuedTasks` and triggers `MetricsCollector.RecordCompletion()` or `RecordFailure()`. Sets task's internal retry counter to `MaxRetries` to prevent automatic re-queuing on health-related failures.",
      "returnValue": "Returns the result `E` from the task's execution and any error `error` that occurred.",
      "exceptions": [
        "errors.New(\"task manager is shutting down\")"
      ],
      "availability": "sync",
      "status": "active",
      "related": {
        "types": [
          "type:Task"
        ],
        "patterns": [
          "pattern:At-most-once task"
        ],
        "errors": [
          "error:task manager is shutting down"
        ]
      }
    },
    "QueueTaskWithPriority": {
      "id": "method:QueueTaskWithPriority",
      "useCase": "To submit a high-priority asynchronous task that will be processed before tasks in the main queue. The caller blocks until the task completes.",
      "signature": "QueueTaskWithPriority[R any, E any](task func(R) (E, error)) (E, error)",
      "parameters": "task: A function `func(R) (E, error)` encapsulating the high-priority work. It receives a resource of type `R` and returns a result `E` or an error.",
      "prerequisites": "The `TaskManager` must be in a running state.",
      "sideEffects": "Adds the task to the priority queue. Increments `PriorityTasks` and triggers `MetricsCollector.RecordArrival()`. Upon completion, decrements `PriorityTasks` and triggers `MetricsCollector.RecordCompletion()` or `RecordFailure()`.",
      "returnValue": "Returns the result `E` from the task's execution and any error `error` that occurred.",
      "exceptions": [
        "errors.New(\"task manager is shutting down\")"
      ],
      "availability": "sync",
      "status": "active",
      "related": {
        "types": [
          "type:Task"
        ],
        "patterns": [
          "pattern:High-priority task with result handling"
        ],
        "errors": [
          "error:task manager is shutting down",
          "error:max retries exceeded"
        ]
      }
    },
    "QueueTaskWithPriorityOnce": {
      "id": "method:QueueTaskWithPriorityOnce",
      "useCase": "To submit a high-priority asynchronous task that, if it fails and `CheckHealth` indicates an unhealthy worker, will NOT be re-queued by Tasker's internal retry mechanism. Useful for non-idempotent high-priority operations.",
      "signature": "QueueTaskWithPriorityOnce[R any, E any](task func(R) (E, error)) (E, error)",
      "parameters": "task: A function `func(R) (E, error)` encapsulating the high-priority work. It receives a resource of type `R` and returns a result `E` or an error.",
      "prerequisites": "The `TaskManager` must be in a running state.",
      "sideEffects": "Adds the task to the priority queue. Increments `PriorityTasks` and triggers `MetricsCollector.RecordArrival()`. Upon completion, decrements `PriorityTasks` and triggers `MetricsCollector.RecordCompletion()` or `RecordFailure()`. Sets task's internal retry counter to `MaxRetries` to prevent automatic re-queuing on health-related failures.",
      "returnValue": "Returns the result `E` from the task's execution and any error `error` that occurred.",
      "exceptions": [
        "errors.New(\"task manager is shutting down\")"
      ],
      "availability": "sync",
      "status": "active",
      "related": {
        "types": [
          "type:Task"
        ],
        "patterns": [
          "pattern:At-most-once task"
        ],
        "errors": [
          "error:task manager is shutting down"
        ]
      }
    },
    "RunTask": {
      "id": "method:RunTask",
      "useCase": "To execute a task immediately and synchronously, bypassing queues. It acquires a resource from the pool or creates a temporary one.",
      "signature": "RunTask[R any, E any](task func(R) (E, error)) (E, error)",
      "parameters": "task: A function `func(R) (E, error)` encapsulating the immediate work. It receives a resource of type `R` and returns a result `E` or an error.",
      "prerequisites": "The `TaskManager` must be in a running state.",
      "sideEffects": "Acquires a resource (from pool or temporary creation), executes the task, then returns/destroys the resource. Triggers `MetricsCollector.RecordArrival()`, `RecordCompletion()`, or `RecordFailure()`.",
      "returnValue": "Returns the result `E` from the task's execution and any error `error` that occurred.",
      "exceptions": [
        "errors.New(\"task manager is shutting down\")",
        "fmt.Errorf(\"failed to create temporary resource: %w\", originalErr)"
      ],
      "availability": "sync",
      "status": "active",
      "related": {
        "types": [
          "type:Task"
        ],
        "patterns": [
          "pattern:Execute an immediate task"
        ],
        "errors": [
          "error:task manager is shutting down",
          "error:failed to create temporary resource"
        ]
      }
    },
    "Stop": {
      "id": "method:Stop",
      "useCase": "To gracefully shut down the TaskManager, allowing all queued and currently executing tasks to complete before releasing resources.",
      "signature": "Stop() error",
      "parameters": "None.",
      "prerequisites": "The `TaskManager` must be in a running state.",
      "sideEffects": "Transitions manager to 'stopping' state, cancels main context, stops burst manager, drains all task queues, waits for all workers to finish, and destroys all resources via `OnDestroy`.",
      "returnValue": "Returns nil on successful graceful shutdown, or an error if the manager is already stopping or killed.",
      "exceptions": [
        "errors.New(\"task manager already stopping or killed\")"
      ],
      "availability": "sync",
      "status": "active",
      "related": {
        "types": [],
        "patterns": [
          "pattern:Graceful shutdown"
        ],
        "errors": []
      }
    },
    "Kill": {
      "id": "method:Kill",
      "useCase": "To immediately terminate the TaskManager, cancelling all running tasks, dropping all queued tasks, and releasing resources without waiting for completion.",
      "signature": "Kill() error",
      "parameters": "None.",
      "prerequisites": "The `TaskManager` must be in a running or stopping state.",
      "sideEffects": "Transitions manager to 'killed' state, cancels main context, stops burst manager, drops all queued tasks, terminates running tasks, waits for all workers to exit, and destroys all resources via `OnDestroy`.",
      "returnValue": "Returns nil on successful immediate shutdown, or an error if the manager is already killed.",
      "exceptions": [
        "errors.New(\"task manager already killed\")"
      ],
      "availability": "sync",
      "status": "active",
      "related": {
        "types": [],
        "patterns": [
          "pattern:Immediate shutdown (e.g., for testing or emergency)"
        ],
        "errors": []
      }
    },
    "Stats": {
      "id": "method:Stats",
      "useCase": "To retrieve real-time operational statistics about the TaskManager's current state.",
      "signature": "Stats() TaskStats",
      "parameters": "None.",
      "prerequisites": "None.",
      "sideEffects": "None.",
      "returnValue": "Returns a `TaskStats` struct containing current worker counts, queue sizes, and resource availability.",
      "exceptions": [],
      "availability": "sync",
      "status": "active",
      "related": {
        "types": [
          "type:TaskStats"
        ],
        "patterns": [
          "pattern:Polling stats and metrics"
        ],
        "errors": []
      }
    },
    "Metrics": {
      "id": "method:Metrics",
      "useCase": "To retrieve comprehensive aggregated performance metrics about task execution, throughput, and reliability.",
      "signature": "Metrics() TaskMetrics",
      "parameters": "None.",
      "prerequisites": "None.",
      "sideEffects": "None (reads aggregated data from the internal or custom `MetricsCollector`).",
      "returnValue": "Returns a `TaskMetrics` struct containing calculated performance indicators like execution times, wait times, and success/failure rates.",
      "exceptions": [],
      "availability": "sync",
      "status": "active",
      "related": {
        "types": [
          "type:TaskMetrics",
          "type:MetricsCollector"
        ],
        "patterns": [
          "pattern:Polling stats and metrics"
        ],
        "errors": []
      }
    },
    "NewRunner": {
      "id": "method:NewRunner",
      "useCase": "Deprecated: Use `NewTaskManager` instead. This function was an alias for `NewTaskManager`.",
      "signature": "NewRunner[R any, E any](config Config[R]) (TaskManager[R, E], error)",
      "parameters": "config: `Config[R]` struct.",
      "prerequisites": "Same as `NewTaskManager`.",
      "sideEffects": "Same as `NewTaskManager`.",
      "returnValue": "Same as `NewTaskManager`.",
      "exceptions": [],
      "availability": "sync",
      "status": "deprecated",
      "related": {
        "types": [
          "type:Config[R]",
          "type:TaskManager"
        ],
        "patterns": [],
        "errors": []
      }
    }
  },
  "decisionTrees": {
    "ChooseTaskSubmissionMethod": {
      "id": "decisionTree:ChooseTaskSubmissionMethod",
      "question": "Which task submission method should I use?",
      "logic": "IF [task is time-sensitive or critical] THEN [IF [task must execute immediately and block caller] THEN [approach: `RunTask`] ELSE [approach: `QueueTaskWithPriority`]] ELSE [approach: `QueueTask`]",
      "validationMethod": "Verify observed task latency and queueing behavior match expected outcomes (e.g., `RunTask` has minimal queue time, `QueueTaskWithPriority` beats `QueueTask` under load).",
      "related": {
        "methods": [
          "method:QueueTask",
          "method:QueueTaskWithPriority",
          "method:RunTask"
        ],
        "patterns": []
      }
    },
    "HandleTaskRetries": {
      "id": "decisionTree:HandleTaskRetries",
      "question": "How should task failures be handled, especially concerning retries?",
      "logic": "IF [task failure means the worker/resource is broken and needs replacement] THEN [approach: implement `Config.CheckHealth` to return `false` for that error] ELSE [approach: treat as task-specific error only (worker continues)]; AND IF [operation is non-idempotent and should not be re-executed by the manager if worker fails] THEN [approach: use `QueueTaskOnce` or `QueueTaskWithPriorityOnce`] ELSE [approach: use standard `QueueTask` or `QueueTaskWithPriority`]",
      "validationMethod": "Observe worker replacement behavior and task retry counts in logs/metrics. Verify non-idempotent tasks are not re-queued by Tasker's internal mechanism.",
      "related": {
        "methods": [
          "method:QueueTaskOnce",
          "method:QueueTaskWithPriorityOnce"
        ],
        "patterns": [
          "pattern:Custom `CheckHealth` for specific errors",
          "pattern:At-most-once task"
        ]
      }
    },
    "ChooseShutdownMethod": {
      "id": "decisionTree:ChooseShutdownMethod",
      "question": "How should the TaskManager be shut down?",
      "logic": "IF [all in-flight and queued tasks must complete] THEN [approach: `manager.Stop()`] ELSE [approach: `manager.Kill()` (to immediately terminate and cancel tasks)]",
      "validationMethod": "Observe whether tasks in queues are processed (`Stop()`) or dropped (`Kill()`) and the time taken for the shutdown call to return.",
      "related": {
        "methods": [
          "method:Stop",
          "method:Kill"
        ],
        "patterns": [
          "pattern:Graceful shutdown",
          "pattern:Immediate shutdown (e.g., for testing or emergency)"
        ]
      }
    },
    "EnableDynamicScaling": {
      "id": "decisionTree:EnableDynamicScaling",
      "question": "Should dynamic worker scaling be enabled?",
      "logic": "IF [workload is highly variable with unpredictable spikes] THEN [approach: enable dynamic scaling by setting `Config.BurstInterval` > 0 and `Config.MaxWorkerCount` appropriately] ELSE [approach: rely on fixed `Config.WorkerCount`]",
      "validationMethod": "Monitor `Stats().BurstWorkers` and `TaskMetrics.TaskArrivalRate` vs `TaskCompletionRate` under load. Confirm workers scale up/down as expected.",
      "related": {
        "methods": [
          "method:Stats",
          "method:Metrics"
        ],
        "patterns": [
          "pattern:Enable dynamic scaling"
        ]
      }
    },
    "ConfigureLoggingAndMetrics": {
      "id": "decisionTree:ConfigureLoggingAndMetrics",
      "question": "How to integrate with custom logging or metrics systems?",
      "logic": "IF [internal Tasker logs are required for debugging or monitoring] THEN [approach: implement `tasker.Logger` and assign to `Config.Logger`] ELSE [use default no-op logger]; AND IF [detailed Tasker performance metrics need to be exposed to an external monitoring system (e.g., Prometheus)] THEN [approach: implement `tasker.MetricsCollector` and assign to `Config.Collector`] ELSE [rely on `manager.Stats()` and `manager.Metrics()` for in-process inspection]",
      "validationMethod": "Verify log output matches custom logger format. Confirm metrics are reported to external systems as expected.",
      "related": {
        "methods": [
          "method:Stats",
          "method:Metrics"
        ],
        "patterns": [
          "pattern:Minimal custom logger",
          "pattern:Simple custom metrics collector (for total tasks completed)"
        ]
      }
    }
  },
  "patterns": {
    "Basic TaskManager Initialization": {
      "id": "pattern:Basic TaskManager Initialization",
      "description": "Demonstrates the minimal configuration and setup required to create a functional `TaskManager` instance.",
      "example": {
        "code": "import (\n    \"context\"\n    \"log\"\n    \"github.com/asaidimu/tasker\"\n)\n\n// Define your resource type\ntype MyResource struct{}\n\n// Implement onCreate and onDestroy functions\nfunc createMyResource() (*MyResource, error) { \n    log.Println(\"Resource created\")\n    return &MyResource{}, nil \n}\nfunc destroyMyResource(r *MyResource) error { \n    log.Println(\"Resource destroyed\")\n    return nil \n}\n\n// Configure and create TaskManager\nconfig := tasker.Config[*MyResource]{\n    OnCreate: createMyResource,\n    OnDestroy: destroyMyResource,\n    WorkerCount: 2,\n    Ctx: context.Background(),\n}\nmanager, err := tasker.NewTaskManager[*MyResource, any](config)\nif err != nil { log.Fatal(err) }\ndefer manager.Stop()",
        "validation": "Manager is successfully initialized and can accept tasks. `createMyResource` and `destroyMyResource` are called during manager lifecycle."
      },
      "related": {
        "methods": [
          "method:NewTaskManager"
        ],
        "errors": [
          "error:worker count must be positive",
          "error:onCreate function is required",
          "error:onDestroy function is required"
        ]
      }
    },
    "Queue task in a goroutine": {
      "id": "pattern:Queue task in a goroutine",
      "description": "Shows how to submit a task to the `TaskManager` asynchronously by wrapping the `QueueTask` call in its own goroutine, allowing the caller to continue execution without blocking.",
      "example": {
        "code": "import (\n    \"fmt\"\n    \"time\"\n    \"github.com/asaidimu/tasker\"\n)\n\n// manager is an initialized tasker.TaskManager\n\ngo func() {\n    taskID := 1\n    result, err := manager.QueueTask(func(res *MyResource) (string, error) {\n        fmt.Printf(\"Worker processing Task %d\\n\", taskID)\n        time.Sleep(100 * time.Millisecond)\n        return fmt.Sprintf(\"Task %d completed\", taskID), nil\n    })\n    if err != nil { \n        fmt.Printf(\"Task %d failed: %v\\n\", taskID, err)\n    } else { \n        fmt.Printf(\"Task %d result: %s\\n\", taskID, result)\n    }\n}()\nfmt.Println(\"Main thread continues immediately.\")\ntime.Sleep(200 * time.Millisecond) // Allow task to run",
        "validation": "The 'Main thread continues immediately.' message appears almost instantly, and the task completion message appears later, confirming asynchronous execution."
      },
      "related": {
        "methods": [
          "method:QueueTask"
        ],
        "errors": [
          "error:task manager is shutting down"
        ]
      }
    },
    "High-priority task with result handling": {
      "id": "pattern:High-priority task with result handling",
      "description": "Demonstrates submitting a task to the high-priority queue and handling its outcome, ensuring it's processed ahead of standard tasks.",
      "example": {
        "code": "import (\n    \"fmt\"\n    \"time\"\n    \"github.com/asaidimu/tasker\"\n)\n\n// manager is an initialized tasker.TaskManager\n\ngo func() {\n    fmt.Println(\"Queueing high-priority task...\")\n    result, err := manager.QueueTaskWithPriority(func(res *MyResource) (string, error) {\n        fmt.Println(\"Worker processing HIGH PRIORITY task!\")\n        time.Sleep(50 * time.Millisecond)\n        return \"Urgent report generated!\", nil\n    })\n    if err != nil { \n        fmt.Printf(\"Urgent task failed: %v\\n\", err)\n    } else { \n        fmt.Printf(\"Urgent task result: %s\\n\", result)\n    }\n}()\n\n// Simultaneously queue a lower priority task\ngo func() {\n    fmt.Println(\"Queueing normal task...\")\n    _, _ = manager.QueueTask(func(res *MyResource) (string, error) {\n        fmt.Println(\"Worker processing normal task.\")\n        time.Sleep(150 * time.Millisecond)\n        return \"Normal task done\", nil\n    })\n}()\ntime.Sleep(300 * time.Millisecond) // Allow tasks to run",
        "validation": "The 'Worker processing HIGH PRIORITY task!' and 'Urgent task result:' messages appear before or significantly faster than messages from the 'normal task', especially if both are queued close together."
      },
      "related": {
        "methods": [
          "method:QueueTaskWithPriority",
          "method:QueueTask"
        ],
        "errors": [
          "error:task manager is shutting down"
        ]
      }
    },
    "Execute an immediate task": {
      "id": "pattern:Execute an immediate task",
      "description": "Illustrates how to execute a task synchronously and immediately using `RunTask`, bypassing the queueing system, and either utilizing a pooled resource or creating a temporary one.",
      "example": {
        "code": "import (\n    \"fmt\"\n    \"time\"\n    \"github.com/asaidimu/tasker\"\n)\n\n// manager is an initialized tasker.TaskManager\n\nfmt.Println(\"Running an immediate task...\")\nimmediateResult, immediateErr := manager.RunTask(func(res *MyResource) (string, error) {\n    fmt.Println(\"IMMEDIATE Task processing fast preview.\")\n    time.Sleep(20 * time.Millisecond)\n    return \"fast_preview.jpg\", nil\n})\nif immediateErr != nil { \n    fmt.Printf(\"Immediate Task Failed: %v\\n\", immediateErr)\n} else { \n    fmt.Printf(\"Immediate Task Completed: %s\\n\", immediateResult)\n}\nfmt.Println(\"Immediate task call returned.\")",
        "validation": "The 'IMMEDIATE Task processing...' message appears before 'Immediate task call returned.', and the call to `RunTask` itself blocks until the task is complete, confirming synchronous execution."
      },
      "related": {
        "methods": [
          "method:RunTask"
        ],
        "errors": [
          "error:task manager is shutting down",
          "error:failed to create temporary resource"
        ]
      }
    },
    "Custom `CheckHealth` for specific errors": {
      "id": "pattern:Custom `CheckHealth` for specific errors",
      "description": "Defines a custom `CheckHealth` function to categorize task errors, signaling `TaskManager` to replace a worker if the error indicates a resource or worker malfunction.",
      "example": {
        "code": "import (\n    \"errors\"\n    \"fmt\"\n    \"github.com/asaidimu/tasker\"\n)\n\n// checkImageProcessorHealth: Custom health check.\n// If the error is \"processor_crash\", consider the worker/resource unhealthy.\nfunc checkImageProcessorHealth(err error) bool {\n    if err != nil && err.Error() == \"processor_crash\" {\n        fmt.Printf(\"WARN: Detected unhealthy error: %v. Worker will be replaced.\\n\", err)\n        return false // This error indicates an unhealthy state\n    }\n    return true // Other errors are just task failures, not worker health issues\n}\n\n// ... in Config ...\nconfig := tasker.Config[*ImageProcessor]{\n    // ...\n    CheckHealth: checkImageProcessorHealth,\n    // ...\n}\n",
        "validation": "When a task returns an error matching `\"processor_crash\"`, the `WARN` message from `checkImageProcessorHealth` appears, and a worker replacement sequence (destroy/create logs) is observed. The task might be re-queued if `MaxRetries` > 0."
      },
      "related": {
        "methods": [
          "method:NewTaskManager"
        ],
        "errors": [
          "error:max retries exceeded"
        ]
      }
    },
    "At-most-once task": {
      "id": "pattern:At-most-once task",
      "description": "Illustrates how to queue a task using `QueueTaskOnce` (or `QueueTaskWithPriorityOnce`) to ensure it is not re-queued by Tasker's internal retry mechanism if it causes an unhealthy worker state. Useful for non-idempotent operations.",
      "example": {
        "code": "import (\n    \"errors\"\n    \"fmt\"\n    \"math/rand\"\n    \"time\"\n    \"github.com/asaidimu/tasker\"\n)\n\n// manager is an initialized tasker.TaskManager with checkHealth configured for \"processor_crash\"\n\ngo func() {\n    fmt.Println(\"Queueing task that might crash (at-most-once)...\")\n    _, err := manager.QueueTaskOnce(func(proc *ImageProcessor) (string, error) {\n        fmt.Println(\"Worker processing at-most-once task.\")\n        time.Sleep(100 * time.Millisecond)\n        if rand.Intn(2) == 0 { // 50% chance to simulate a crash\n            return \"\", errors.New(\"processor_crash\") // This triggers CheckHealth to return false\n        }\n        return \"processed_once_successfully\", nil\n    })\n    if err != nil { \n        fmt.Printf(\"At-most-once task finished with error: %v\\n\", err)\n    } else { \n        fmt.Println(\"At-most-once task completed successfully.\")\n    }\n}()\ntime.Sleep(300 * time.Millisecond) // Allow task to run",
        "validation": "If the task returns `\"processor_crash\"`, `CheckHealth` is triggered, the worker is replaced, but the task's final error (e.g., `processor_crash`) is immediately returned to the caller of `QueueTaskOnce` without any internal retries by Tasker."
      },
      "related": {
        "methods": [
          "method:QueueTaskOnce",
          "method:QueueTaskWithPriorityOnce"
        ],
        "errors": [
          "error:max retries exceeded"
        ]
      }
    },
    "Enable dynamic scaling": {
      "id": "pattern:Enable dynamic scaling",
      "description": "Shows how to configure Tasker to automatically scale its worker count up and down based on real-time task arrival and completion rates.",
      "example": {
        "code": "import (\n    \"context\"\n    \"time\"\n    \"github.com/asaidimu/tasker\"\n)\n\n// Assume MyResource, createMyResource, destroyMyResource, checkMyHealth are defined\n\nconfig := tasker.Config[*MyResource]{\n    OnCreate:      createMyResource,\n    OnDestroy:     destroyMyResource,\n    WorkerCount:   2,                     // Base workers\n    MaxWorkerCount: 10,                    // Max total workers (base + burst)\n    Ctx:           context.Background(),\n    BurstInterval: 100 * time.Millisecond, // Check every 100ms for scaling\n    MaxRetries:    1,\n}\nmanager, err := tasker.NewTaskManager[*MyResource, any](config)\nif err != nil { log.Fatal(err) }\ndefer manager.Stop()",
        "validation": "Monitor `manager.Stats().BurstWorkers` and `manager.Metrics().TaskArrivalRate`/`TaskCompletionRate`. When `TaskArrivalRate` significantly exceeds `TaskCompletionRate`, `BurstWorkers` should increase. When the load subsides, `BurstWorkers` should decrease."
      },
      "related": {
        "methods": [
          "method:NewTaskManager",
          "method:Stats",
          "method:Metrics"
        ],
        "errors": []
      }
    },
    "Graceful shutdown": {
      "id": "pattern:Graceful shutdown",
      "description": "Demonstrates the recommended way to shut down the `TaskManager`, ensuring all pending and in-flight tasks complete before resources are released.",
      "example": {
        "code": "import (\n    \"context\"\n    \"log\"\n    \"time\"\n    \"github.com/asaidimu/tasker\"\n)\n\n// Assume MyResource, createMyResource, destroyMyResource are defined\n\nconfig := tasker.Config[*MyResource]{ /* ... */ Ctx: context.Background() }\nmanager, err := tasker.NewTaskManager[*MyResource, any](config)\nif err != nil { log.Fatal(err) }\n\n// Defer Stop() call ensures graceful shutdown on main exit\ndefer func() {\n    log.Println(\"Initiating graceful shutdown...\")\n    err := manager.Stop()\n    if err != nil { log.Printf(\"Error during graceful shutdown: %v\", err) }\n    log.Println(\"TaskManager gracefully shut down.\")\n}()\n\n// Queue some tasks that will run to completion\nfor i := 0; i < 3; i++ {\n    go func(id int) {\n        _, _ = manager.QueueTask(func(res *MyResource) (string, error) {\n            log.Printf(\"Task %d processing...\\n\", id)\n            time.Sleep(100 * time.Millisecond)\n            return \"Done\", nil\n        })\n    }(i)\n}\n\ntime.Sleep(50 * time.Millisecond) // Allow some tasks to queue/start\nlog.Println(\"Main function exiting, defer will call manager.Stop()...\")",
        "validation": "All 'Task X processing...' messages and 'Task X completed' messages are printed, and `manager.Stop()` returns without error, indicating all tasks finished before shutdown."
      },
      "related": {
        "methods": [
          "method:Stop"
        ],
        "errors": [
          "error:task manager is shutting down"
        ]
      }
    },
    "Immediate shutdown (e.g., for testing or emergency)": {
      "id": "pattern:Immediate shutdown (e.g., for testing or emergency)",
      "description": "Illustrates how to forcefully terminate the `TaskManager`, cancelling active tasks and dropping queued ones, prioritizing speed over task completion.",
      "example": {
        "code": "import (\n    \"context\"\n    \"log\"\n    \"time\"\n    \"github.com/asaidimu/tasker\"\n)\n\n// Assume MyResource, createMyResource, destroyMyResource are defined\n\nconfig := tasker.Config[*MyResource]{ /* ... */ Ctx: context.Background() }\nmanager, err := tasker.NewTaskManager[*MyResource, any](config)\nif err != nil { log.Fatal(err) }\n\n// Queue some tasks, some of which might be dropped\nfor i := 0; i < 5; i++ {\n    go func(id int) {\n        _, taskErr := manager.QueueTask(func(res *MyResource) (string, error) {\n            log.Printf(\"Task %d processing...\\n\", id)\n            time.Sleep(500 * time.Millisecond) // Long-running task\n            return \"Done\", nil\n        })\n        if taskErr != nil { log.Printf(\"Task %d finished with error: %v\\n\", id, taskErr) }\n    }(i)\n}\n\ntime.Sleep(50 * time.Millisecond) // Allow some tasks to queue\nlog.Println(\"Initiating immediate shutdown...\")\nerr = manager.Kill()\nif err != nil { log.Printf(\"Error during immediate shutdown: %v\", err) }\nlog.Println(\"TaskManager immediately shut down.\")\ntime.Sleep(100 * time.Millisecond) // Give time for messages to print",
        "validation": "`manager.Kill()` returns quickly. Not all 'Task X processing...' messages might appear or complete, and some tasks might report errors like 'task manager is shutting down' or 'context canceled', indicating they were interrupted or dropped."
      },
      "related": {
        "methods": [
          "method:Kill"
        ],
        "errors": [
          "error:task manager is shutting down"
        ]
      }
    },
    "Polling stats and metrics": {
      "id": "pattern:Polling stats and metrics",
      "description": "Shows how to periodically retrieve and print the `TaskManager`'s operational statistics and performance metrics.",
      "example": {
        "code": "import (\n    \"context\"\n    \"fmt\"\n    \"time\"\n    \"github.com/asaidimu/tasker\"\n)\n\n// manager is an initialized tasker.TaskManager\n\nticker := time.NewTicker(1 * time.Second)\ndone := make(chan struct{})\ngo func() {\n    for {\n        select {\n        case <-ticker.C:\n            stats := manager.Stats()\n            metrics := manager.Metrics()\n            fmt.Printf(\"Stats: Active=%d, Queued=%d (Prio=%d), AvailRes=%d\\n\",\n                stats.ActiveWorkers, stats.QueuedTasks, stats.PriorityTasks, stats.AvailableResources)\n            fmt.Printf(\"Metrics: ArrivalRate=%.2f/s, AvgExecTime=%s, SuccessRate=%.2f\\n\",\n                metrics.TaskArrivalRate, metrics.AverageExecutionTime, metrics.SuccessRate)\n        case <-done:\n            ticker.Stop()\n            return\n        }\n    }\n}()\n\n// Simulate some work or wait\ntime.Sleep(5 * time.Second)\n\nclose(done) // Stop the monitoring goroutine",
        "validation": "Console output regularly displays updated statistics and metrics, reflecting changes in worker count, queue size, and task rates as tasks are submitted and completed."
      },
      "related": {
        "methods": [
          "method:Stats",
          "method:Metrics"
        ],
        "errors": []
      }
    },
    "Minimal custom logger": {
      "id": "pattern:Minimal custom logger",
      "description": "Provides a basic implementation of the `tasker.Logger` interface that prints Tasker's internal log messages to the console using `log.Printf`.",
      "example": {
        "code": "import \"log\"\nimport \"github.com/asaidimu/tasker\"\n\ntype ConsoleLogger struct{}\n\nfunc (ConsoleLogger) Debugf(format string, args ...any) { log.Printf(\"DEBUG: \"+format, args...) }\nfunc (ConsoleLogger) Infof(format string, args ...any)  { log.Printf(\"INFO: \"+format, args...) }\nfunc (ConsoleLogger) Warnf(format string, args ...any)  { log.Printf(\"WARN: \"+format, args...) }\nfunc (ConsoleLogger) Errorf(format string, args ...any) { log.Printf(\"ERROR: \"+format, args...) }\n\n// Usage in Tasker Config:\n// config.Logger = ConsoleLogger{}\n",
        "validation": "When the TaskManager is running, `log.Printf` output should include Tasker's internal messages prefixed with 'DEBUG:', 'INFO:', 'WARN:', or 'ERROR:'."
      },
      "related": {
        "methods": [
          "method:NewTaskManager"
        ],
        "errors": []
      }
    },
    "Simple custom metrics collector (for total tasks completed)": {
      "id": "pattern:Simple custom metrics collector (for total tasks completed)",
      "description": "An example of a minimal `tasker.MetricsCollector` implementation that only tracks the total number of completed tasks.",
      "example": {
        "code": "import \"sync/atomic\"\nimport \"github.com/asaidimu/tasker\"\n\ntype CounterCollector struct { \n    totalCompleted atomic.Uint64 \n}\n\nfunc (c *CounterCollector) RecordArrival() {} \nfunc (c *CounterCollector) RecordCompletion(s tasker.TaskLifecycleTimestamps) { \n    c.totalCompleted.Add(1) \n}\nfunc (c *CounterCollector) RecordFailure(s tasker.TaskLifecycleTimestamps) {} \nfunc (c *CounterCollector) RecordRetry() {} \n\nfunc (c *CounterCollector) Metrics() tasker.TaskMetrics { \n    return tasker.TaskMetrics{TotalTasksCompleted: c.totalCompleted.Load()} \n}\n\n// Usage in Tasker Config:\n// config.Collector = &CounterCollector{}\n",
        "validation": "After tasks are completed, retrieving `manager.Metrics().TotalTasksCompleted` (or accessing the `totalCompleted` field of `CounterCollector` directly) should reflect the correct count of completed tasks."
      },
      "related": {
        "methods": [
          "method:NewTaskManager",
          "method:Metrics"
        ],
        "errors": []
      }
    }
  },
  "errors": {
    "task manager is shutting down": {
      "id": "error:task manager is shutting down",
      "type": "error",
      "symptoms": "Calls to `QueueTask`, `QueueTaskWithPriority`, `QueueTaskOnce`, `QueueTaskWithPriorityOnce`, or `RunTask` immediately return this specific error.",
      "properties": "None (standard Go error).",
      "scenarios": [
        {
          "trigger": "Attempting to queue a task after `manager.Stop()` has been called.",
          "example": "import \"github.com/asaidimu/tasker\"\n// manager is an initialized TaskManager\nmanager.Stop()\n_, err := manager.QueueTask(func(r *MyResource) (int, error) { return 1, nil })\n// err will be 'task manager is shutting down'",
          "reason": "The TaskManager has transitioned to a 'stopping' or 'killed' state and will no longer accept new tasks."
        },
        {
          "trigger": "Attempting to queue a task after `manager.Kill()` has been called.",
          "example": "import \"github.com/asaidimu/tasker\"\n// manager is an initialized TaskManager\nmanager.Kill()\n_, err := manager.QueueTaskWithPriority(func(r *MyResource) (int, error) { return 1, nil })\n// err will be 'task manager is shutting down'",
          "reason": "The TaskManager has been forcefully terminated and new tasks are rejected."
        }
      ],
      "diagnosis": "Check the application's shutdown logic and ensure that task submission stops before the TaskManager's shutdown methods are invoked.",
      "resolution": "Only submit tasks when the TaskManager is in an active running state. Design task producers to cease operation gracefully when a shutdown is initiated.",
      "prevention": "Implement state checks in task submission pathways to prevent queuing tasks when the manager is no longer accepting them. For instance, a global cancellation context for the entire application that triggers Tasker's shutdown should also signal task producers to stop.",
      "handlingPatterns": "```go\nresult, err := manager.QueueTask(myTaskFunc)\nif err != nil {\n    if errors.Is(err, errors.New(\"task manager is shutting down\")) {\n        log.Println(\"Cannot queue task: TaskManager is shutting down.\")\n        // Gracefully handle the un-queued task, perhaps add to a dead-letter queue or retry later\n    } else {\n        log.Printf(\"Task failed with other error: %v\", err)\n    }\n}\n```",
      "propagationBehavior": "Returned directly to the caller of the task submission method (`QueueTask`, `RunTask`, etc.)."
    },
    "worker count must be positive": {
      "id": "error:worker count must be positive",
      "type": "error",
      "symptoms": "`tasker.NewTaskManager` returns this error during initialization.",
      "properties": "None (standard Go error).",
      "scenarios": [
        {
          "trigger": "Initializing `TaskManager` with `Config.WorkerCount` set to 0.",
          "example": "import \"github.com/asaidimu/tasker\"\nconfig := tasker.Config[*CalculatorResource]{ WorkerCount: 0 /* ... other required fields ... */ }\n_, err := tasker.NewTaskManager[*CalculatorResource, int](config)\n// err will be 'worker count must be positive'",
          "reason": "The `TaskManager` requires at least one worker to manage tasks; a count of zero is invalid."
        },
        {
          "trigger": "Initializing `TaskManager` with `Config.WorkerCount` set to a negative number (e.g., -1).",
          "example": "import \"github.com/asaidimu/tasker\"\nconfig := tasker.Config[*CalculatorResource]{ WorkerCount: -1 /* ... */ }\n_, err := tasker.NewTaskManager[*CalculatorResource, int](config)\n// err will be 'worker count must be positive'",
          "reason": "Negative worker counts are logically impossible and indicate a configuration error."
        }
      ],
      "diagnosis": "Inspect the `WorkerCount` field in the `tasker.Config` struct passed to `NewTaskManager`.",
      "resolution": "Set `Config.WorkerCount` to a positive integer (e.g., 1, 2, or more) based on your concurrency needs.",
      "prevention": "Implement configuration validation in your application before creating the `TaskManager`.",
      "handlingPatterns": "```go\nmanager, err := tasker.NewTaskManager(config)\nif err != nil {\n    log.Fatalf(\"Failed to initialize TaskManager: Invalid worker count: %v\", err) // Typically fatal at startup\n}\n```",
      "propagationBehavior": "Returned immediately by `NewTaskManager`."
    },
    "onCreate function is required": {
      "id": "error:onCreate function is required",
      "type": "error",
      "symptoms": "`tasker.NewTaskManager` returns this error during initialization.",
      "properties": "None (standard Go error).",
      "scenarios": [
        {
          "trigger": "Initializing `TaskManager` with `Config.OnCreate` set to `nil`.",
          "example": "import \"github.com/asaidimu/tasker\"\nconfig := tasker.Config[*CalculatorResource]{ OnCreate: nil /* ... other required fields ... */ }\n_, err := tasker.NewTaskManager[*CalculatorResource, int](config)\n// err will be 'onCreate function is required'",
          "reason": "The `TaskManager` must know how to create new instances of the resource `R` for its workers and internal pool."
        }
      ],
      "diagnosis": "Check the `OnCreate` field in the `tasker.Config` struct.",
      "resolution": "Provide a non-nil function for `Config.OnCreate` that implements the logic for creating your resource `R`.",
      "prevention": "Ensure `OnCreate` is always assigned a valid function during configuration.",
      "handlingPatterns": "Same as `worker count must be positive` - typically a fatal error during application startup.",
      "propagationBehavior": "Returned immediately by `NewTaskManager`."
    },
    "onDestroy function is required": {
      "id": "error:onDestroy function is required",
      "type": "error",
      "symptoms": "`tasker.NewTaskManager` returns this error during initialization.",
      "properties": "None (standard Go error).",
      "scenarios": [
        {
          "trigger": "Initializing `TaskManager` with `Config.OnDestroy` set to `nil`.",
          "example": "import \"github.com/asaidimu/tasker\"\nconfig := tasker.Config[*CalculatorResource]{ OnDestroy: nil /* ... other required fields ... */ }\n_, err := tasker.NewTaskManager[*CalculatorResource, int](config)\n// err will be 'onDestroy function is required'",
          "reason": "The `TaskManager` must know how to properly clean up resources when workers are shut down or resources are no longer needed."
        }
      ],
      "diagnosis": "Check the `OnDestroy` field in the `tasker.Config` struct.",
      "resolution": "Provide a non-nil function for `Config.OnDestroy` that implements the logic for destroying/cleaning up your resource `R`.",
      "prevention": "Ensure `OnDestroy` is always assigned a valid function during configuration.",
      "handlingPatterns": "Same as `worker count must be positive` - typically a fatal error during application startup.",
      "propagationBehavior": "Returned immediately by `NewTaskManager`."
    },
    "failed to create temporary resource": {
      "id": "error:failed to create temporary resource",
      "type": "Go wrapped error",
      "symptoms": "`RunTask` returns an error with this message, typically wrapping an underlying error from your `OnCreate` function.",
      "properties": "The original error from `Config.OnCreate` is wrapped. Can be unwrapped using `errors.Unwrap(err)`.",
      "scenarios": [
        {
          "trigger": "`RunTask` is called, and the resource pool is either empty or `ResourcePoolSize` is 0, forcing a temporary resource creation via `Config.OnCreate`, which then fails.",
          "example": "import \"errors\"\nimport \"github.com/asaidimu/tasker\"\n// If createImageProcessor returns an error during temporary creation\nmanager.RunTask(func(proc *ImageProcessor) (string, error) { return \"ok\", nil })\n// This call returns error like 'failed to create temporary resource: connection refused'",
          "reason": "The `OnCreate` function failed to provision a resource when `RunTask` needed a new one. This could be due to network issues, credential problems, or external service unavailability."
        }
      ],
      "diagnosis": "Unwrap the error to inspect the root cause. This points to a problem in your `Config.OnCreate` function or its external dependencies.",
      "resolution": "Address the underlying issue causing `OnCreate` to fail. This might involve ensuring network connectivity, correcting API keys, or handling transient external service errors within `OnCreate` itself.",
      "prevention": "Make your `OnCreate` function robust by adding retry logic or specific error handling for common transient issues with external dependencies. Consider increasing `ResourcePoolSize` to reduce the frequency of temporary resource creation if `OnCreate` is slow or prone to failures.",
      "handlingPatterns": "```go\n_, err := manager.RunTask(myImmediateTaskFunc)\nif err != nil {\n    if errors.Is(err, errors.New(\"failed to create temporary resource\")) {\n        log.Printf(\"Immediate task aborted due to resource provisioning error: %v\", errors.Unwrap(err))\n        // Handle by notifying user, logging, or retrying at application level\n    } else {\n        log.Printf(\"Immediate task failed for another reason: %v\", err)\n    }\n}\n```",
      "propagationBehavior": "Returned directly to the caller of `RunTask`."
    },
    "max retries exceeded": {
      "id": "error:max retries exceeded",
      "type": "Go wrapped error",
      "symptoms": "A `QueueTask` or `QueueTaskWithPriority` call eventually returns this error after internal retries. The wrapped error is the one that repeatedly caused the `CheckHealth` function to return `false`.",
      "properties": "The original error that triggered the unhealthy state is wrapped. Can be unwrapped using `errors.Unwrap(err)`.",
      "scenarios": [
        {
          "trigger": "A task repeatedly fails, and for each failure, `Config.CheckHealth` returns `false` (indicating an unhealthy worker/resource). After `Config.MaxRetries` attempts, the task is finally marked as failed.",
          "example": "import \"errors\"\nimport \"github.com/asaidimu/tasker\"\n// Assume CheckHealth returns false for 'processor_crash'\n_, err := manager.QueueTask(func(proc *ImageProcessor) (string, error) {\n    return \"\", errors.New(\"processor_crash\") // This task will be retried MaxRetries times\n})\n// After MaxRetries attempts, err will be 'max retries exceeded: processor_crash'",
          "reason": "The task consistently causes an unhealthy worker/resource state, and Tasker has exhausted all configured attempts to run it on a new worker."
        }
      ],
      "diagnosis": "The true problem lies in the original error that repeatedly triggers `CheckHealth` to return `false`. Debug the task logic and its interaction with the resource to understand why it's failing persistently.",
      "resolution": "Fix the underlying cause of the persistent unhealthy failures. This might require addressing issues in external services, modifying task input, or improving the robustness of your resource (`R`). Adjust `Config.MaxRetries` if the issue is truly transient but requires more attempts.",
      "prevention": "Improve `CheckHealth` precision (only return `false` for genuine worker/resource issues), enhance resource robustness, or ensure task idempotency so that retries are always safe.",
      "handlingPatterns": "```go\n_, err := manager.QueueTask(myProblematicTaskFunc)\nif err != nil {\n    if errors.Is(err, errors.New(\"max retries exceeded\")) {\n        originalErr := errors.Unwrap(err)\n        log.Printf(\"Task failed permanently after retries. Original cause: %v\", originalErr)\n        // This indicates a critical failure. Alert monitoring, dead-letter task, or trigger human intervention.\n    } else {\n        log.Printf(\"Task failed with other error: %v\", err)\n    }\n}\n```",
      "propagationBehavior": "Returned to the caller of `QueueTask` or `QueueTaskWithPriority`. Tasks submitted with `QueueTaskOnce` or `QueueTaskWithPriorityOnce` will return the original unhealthy error directly without wrapping in \"max retries exceeded\" if they fail due to an unhealthy worker."
    }
  }
}